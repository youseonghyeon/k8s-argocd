replicaCount: 1

image:
  repository: nginx
  pullPolicy: IfNotPresent
  tag: ""
imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  create: true
  automount: true
  annotations: {}
  name: ""

podAnnotations: {}
podLabels: {}
podSecurityContext: {}
securityContext: {}

service:
  type: ClusterIP
  port: 80

ingress:
  enabled: false
  className: ""
  annotations: {}
  hosts:
    - host: chart-example.local
      paths:
        - path: /
          pathType: ImplementationSpecific
  tls: []

httpRoute:
  enabled: false
  annotations: {}
  parentRefs:
  - name: gateway
    sectionName: http
    hostnames:
  - chart-example.local
  rules:
  - matches:
    - path:
        type: PathPrefix
        value: /headers

resources: {}
livenessProbe:
  httpGet:
    path: /
    port: http
readinessProbe:
  httpGet:
    path: /
    port: http

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 100
  targetCPUUtilizationPercentage: 80

volumes: []
volumeMounts: []
nodeSelector: {}
tolerations: []
affinity: {}

# --- Elasticsearch 설정 ---
elasticsearch:
  enabled: true
  replicas: 1
  minimumMasterNodes: 1
  persistence:
    enabled: false  # 스토리지 없어도 바로 뜨게 설정
  antiAffinity: "soft"
  esConfig:
    elasticsearch.yml: |
      xpack.security.enabled: false
      xpack.security.http.ssl.enabled: false
      xpack.security.transport.ssl.enabled: false
  resources:
    requests: { cpu: "100m", memory: "512Mi" }
    limits: { cpu: "1000m", memory: "1Gi" }

# --- Logstash 설정 ---
logstash:
  enabled: true    # 이 줄이 없으면 헬름이 템플릿을 생성하지 않습니다.
  replicaCount: 1
  persistence:
    enabled: false # 디스크 권한 문제 방지를 위해 비활성화

  logstashConfig:
    logstash.yml: |
      http.host: "0.0.0.0"
      pipeline.ordered: auto

  pipeline:
    main.conf: |
      input {
        kafka {
          bootstrap_servers => "my-cluster-kafka-bootstrap.infra.svc.cluster.local:9092"
          topics => ["spring-boot-logs"]
          codec => "json"
          group_id => "logstash-group"
        }
      }
      filter {
        if [kubernetes][container][name] == "infra" {
          mutate { add_tag => ["nginx-logs"] }
        }
      }
      output {
        elasticsearch {
          # 도메인 주소를 전체 주소(FQDN)로 작성하여 DNS 에러 방지
          hosts => ["http://elasticsearch-master.infra.svc.cluster.local:9200"]
          index => "k8s-logs-%{+YYYY.MM.dd}"
        }
      }
  resources:
    requests: { cpu: "100m", memory: "512Mi" }
    limits: { cpu: "1000m", memory: "1Gi" }

kibana:
  protocol: http
  setupJob:
    enabled: false
    createNextToken: false
  secretMounts:
    - name: elasticsearch-master-certs
      secretName: elasticsearch-master-certs
      path: /usr/share/kibana/config/certs
  kibanaConfig:
    kibana.yml: |
      server.host: "0.0.0.0"
      elasticsearch.hosts: ["http://elasticsearch-master:9200"]
      elasticsearch.ssl.verificationMode: none
  service:
    type: NodePort # 외부 접속을 위해 NodePort나 Ingress 설정
    port: 5601


filebeat:
  extraVolumes: [ ]
  extraVolumeMounts: [ ]
  secretMounts: [ ]
  indexManagement:
    enabled: false
  extraEnvs:
    - name: ELASTICSEARCH_HOSTS
      value: ""
  daemonset:
    enabled: true
    filebeatConfig:
      filebeat.yml: |
        filebeat.inputs:
        - type: container
          paths:
            - /var/log/containers/*.log
          # 이 부분에 아래 설정을 추가하여 경로 미스매치를 해결합니다.
          processors:
            - add_kubernetes_metadata:
                host: ${NODE_NAME}
                matchers:
                  - logs_path:
                      logs_path: "/var/log/containers/"
            - decode_json_fields:
                fields: ["message"]
                target: ""
                overwrite_keys: true

        output.kafka:
          hosts: ["my-cluster-kafka-bootstrap.infra.svc.cluster.local:9092"]
          topic: "spring-boot-logs"
          partition.round_robin:
            reachable_only: true
          required_acks: 1
          compression: gzip
